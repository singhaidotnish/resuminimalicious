{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# How Modern LLMs Work \u2013 Demo Notebook\n",
        "\n",
        "This notebook demonstrates a tiny language model workflow.\n",
        "\n",
        "\ud83d\udc49 You can run this notebook directly in **Google Colab** (Runtime \u2192 Run all).\n",
        "\n",
        "---\n",
        "## Quick Intro\n",
        "We'll use Hugging Face's `transformers` library with a small pretrained model to generate text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install transformers if not already installed (uncomment if needed)\n",
        "# !pip install transformers torch\n",
        "\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load a small model (distilgpt2 runs even on CPU)\n",
        "generator = pipeline('text-generation', model='distilgpt2')\n",
        "result = generator(\"Once upon a time\", max_length=50, num_return_sequences=1)\n",
        "print(result[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Next Steps\n",
        "- Try changing the prompt text.\n",
        "- Modify `max_length` or `num_return_sequences`.\n",
        "- Explore other models on [Hugging Face Hub](https://huggingface.co/models).\n",
        "\n",
        "That's it! \ud83c\udf89 You've run a mini LLM demo."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}